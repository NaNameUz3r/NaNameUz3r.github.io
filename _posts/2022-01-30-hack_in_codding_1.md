---
title: "Врубаемся в программирование"
tags: "Программирование Отчеты"
lang: ru
show_edit_on_github: false
comment: true
license: false
modify_date: "2022-01-30"
show_subscribe: false
article_header:
  theme: dark
  type: overlay
  align: left
  background_image:
    src: /header_images/hack_in_codding_1.jpg
---

Научный взгляд на программирование. Concurrency, atomicity и кое что ещё.
<!--more-->

Сейчас я прохожу курс Бобровского Сергея Игоревича, который называется "Как понять в программировании всё". На самом деле это цикл курсов, направленный на освоение научного, или лучше сказать — инженерного взгляда на программироваание, от фундаментальных концепций до осмысления *парадигм* программирования.

Этот пост является своего рода отчетом о пройденном материале. Хочу сфокусироваться на теме параллельного программирования и атомарности — я застрял на тесте по этой теме :), надеюсь вместе мы разберемся. В дополнение я постараюсь освятить некоторые важные концепции. Остальная часть курса, которая в этом после не затрагивается, либо связана с синтаксисом и особенностями мультипарадигмального языка программирования Julia, либо это отдельные и сложные концепции, которые мы затроули пока лишь поверхностно, но обязательно вернемся к их углубленному изучению позже (или я их плохо понял). Lets rock.

### Что там научного-то?

В посте про [сложность алгоритмов](/2022/01/22/algorithms_complexity.html) я пытался развить мысль о том, что программирование — дитя математики, и подходить к анализу и понимаю алгоритмов нужно с научно-математической позиции мышления, а не с интуитивно-наивной. С программированием всё обстоит точно-так же. Чтобы разрабатывать эффективные и надежные программные системы необходимо понимать как работает "под капотом" сама система, и инструменты которые для разработки этой системы используются (языки программирования, парадигмы или подходы к программированию, etc.).

### Фундаментальные концепции

#### Переменная

Программе, или алгоритму, в процессе работы необходимо "пространство" в котором будут "производиться вычисления". Этим пространством является оперативная память и процессорные кеши. Их устройство это отдельная и сложная тема, сейчас нам нужно понимать что есть некоторый *ресурс* в который программа может быстро записывать какие-то данные, и читать их откуда.

Проще всего представить оперативную память как набор ячеек у каждой из которых есть адрес. По этому адресу к ячейками можно *получить доступ*. В данном случае имеются в виду **физические** ячейки оперативной памяти.

В коде программы, в частном случае, мы напрямую (явно) с этими адресами не работаем, а используем *переменные*,к которым привязываем *значения*. Имя переменной — это её идентификатор, а значениями являются какие-то данные, которые мы этому этому имени *присваиваем*, чаще всего с помощью оператора "=".

Ещё более научно это называется *именованным состоянием*, что уже чуть более сложная концепция, которая является одной из главных характеристик в *любой* парадигме программирования, а её реализация (степень поддержки) зависит от конкретно рассматриваемой парадигмы.

В общем и целом, *состояние* — это "способность" программы запоминать данные (присвоенные значения),и в будущем с ними как-то работать. Если состояние имеет идентификатор, то есть, напрямую и явно доступно для операций в ходе программирования, то оно называется *"именованным состояним"*. Да, состояния могут не иметь идентификаторов и быть своего рода *безымянными*.

##### Зачем идентификаторы, есть у ячеек есть адреса?

Во-первых, как я уже писал, мы с адресами напрямую не работаем. Во-вторых, на самом деле значения ячейкам памяти присваиваются как "константа", то есть "на постоянку", или однократно.

*"Однократное присваивание"* это одна из фундаментальных концепций программирования, суть которой заключается в том, что как только в коде определяется новая переменная (некоторому идентификатору присваивется его "первое" значение), эта переменная становится неизменяемой (иммутабельной).

Подождите, но я могу сделать в своем любимом пайтоне что-то вроде: my_special_var = "hello dear friend", и следом my_special_var = "goodbye fella", и расшибусь головой о стену от уверенности в том что print(my_special_var) вернёт последнюю строку — "goodbye fella". Всё так! Просто почти во всех современных языках программирования кроме концепции однократного присваивания переменных существует дополнительный механизм — "явное определение", которое позволяет присвоить *новые* значения уже *существующему* идентификатору. Но для записи данных использоваться, как правило, будет **не та же самая ячейка памяти**, а новая и с другим адресом. *Тот же самый, уже существующий идентификатор (имя переменной)* будет связан с другой областью памяти, в которую будет записано новое значение.

Не увлекайтесь "явным *переопределением*", это удобно, но есть один **серьезный минус** — потенциально эта возможность легкого переопределения приводит к куче ошибок. Относитесь к переменным чутко и ответствено, используйте адекватный нейминг. Старайтесь не переопределять уже существующие переменные (если нужно, используйте новые имена соответствующие контексту изменений и "смыслу кода"). Но так же не стоит плодить явно лишние переменные, а необходимые определяйте в непосредственной близости к коду, в котором эти переменные используются. Это короткое отступление о базовых приницпах "ясного стиля" программирования :)

### Опять математика?

Как было сказано ранее, реализация "способности запоминать состояния" определяется поддерживаемыми языком программирования парадигмами программирования.


{:refdef: style="text-align: center;"}
![Взрыв Мозга](/images/mind_blowing.gif)
{: refdef}
*<center>Поддерживаемые языком программирования парадигмы программирования — Чего-чего? </center>*

Не волнуйтесь, мы разберемся.

#### Парадигма программирования

Парадигмой программирования, грубо говоря, называется определённый подход к программной разработке. Правильно говоря — это не менее чем **настоящее** научное открытие, строго выверенная математическая теории, которая на практике воплащается в таких сложных программных системах как *языки программированя*. Это не значит что язык программирования конструируется на базе одной парадигмы, напротив — многие современные языки являются мультипарадигмальными, из чего следует вывод что это *ну очень сложные математические модели*.

*Хорошая новость в том, что если что-то придумали одни люди, мы можем в этом разобраться, пусть даже приложив N усилия!*

Так вот, эта математическая модель выражается как *семантика языка программирования*, которая передает смысл конструкций (и инструкций) в конкретном языке.

Подробное изучение парадигм программирования явно выходит за рамки этого поста и моих текущих знаний, но в будущем эти темы будут подробнее изучаться на соответсвующих курсах, до которых я надеюсь добраться, а значит о них будут написаны подобные посты-отчеты.

---

Способ реализации *именованного состояния* является одной из двух ключевых характеристик парадигм программирования. Вторая характеристика — характерность или не характерность **недетерминизма**.

#### Недетерминизм

В привычном представлении новичка-программиста, особенно самоучки, обычная императивная программа выполняется последовательно и выдает от вызова к вызову, с одними и теми-же аргументами, один и тот-же результат. Такое поведение назвыается **детерминированным**. Иными словами, если программа детерминирована, мы можем по её коду однозначно определить какой результат будет получен на выходе. Никаких сюрпризов.

Недетерминизм, как несложно предположить, является противоположной ситуацией, когда вызывая программу, даже с одними и теми же входными данными, мы можем наблюдать разный результат из раза в раз. Такой недетерминизм называется *явным*.

Но как такое получается? Программа может выдавать неожиданные результаты, если она описана в системе (парадигме) программирования, в которой соединяются уже изученные нами "именованные состояния" и ***параллельные*** вычисления.

### Параллелизм

Наконец мы подобрались к параллелизму! Сперва нам нужно строго определять о чем идет речь. В русском языке часто используется одно и то же слово для фактически разных концепции.

Во-первых, есть parallelism — аппаратная концепция. Это про "одновременное" выполнение процессорных инструкций на нескольких ядрах, etc.

Во-вторых, concurrency — чисто программная концепция, которая нас интересует в первую очередь в рамках этой темы.

---

Вернемся к связи недетерминизма с параллельными вычислениями и именованными состояниями. В теме программного параллелизма есть две разные концепции:
- Процесс
- и Thread (нить).

Вспоминая свое начальное обучение на администратора баз данных, одно из самых ярких впечатлений на тот момент у меня вызвало простое, но чертовски понятное определение разницы этих двух терминов, которое я услышал в одой из лекций Дмитрия Кетова на тему устройства Линукса. Дословно не помню, но суть такая:

"Процесс — вычисления работающие в **изолированной** модели памяти. Нити — работают в модели **общей** памяти."

Иными словами, Нити — это параллельные "процессы" которые могу иметь\имеют доступ к одним и тем же *именованным состояниям* (модель "общей" памяти).

Теперь должно стать понятно откуда могут взяться "неожиданные", недетерминированные результаты работы кода. Если в программе используются параллельные потоки (нити), которые работают с одними и теми-же переменными, мы **вообще** не можем знать в каком порядке эти нити буду запущены, изменят значения переменной и завершатся. В таких условиях работы возникает *race condition*, по русски — "состояние гонки". Смысл этого термина в том, что "победителем" гонки будет нить, которая последней запишет в переменную результат своей работы. Отсюда и возникает *явный недетерминизим*, мы видим его в непосредственном результате работы программы.

Хотя существуют ситуации, в которых недетерминизм приемлем или даже необходим (является целевым, ожидаемым поведением), чаще всего мы хотим чтобы наши программы были детерминированы (надежны и стабильны), даже если мы применяем параллельные вычисления, например, используя их для ускорения работы программы.

Такой результат может быть достигнут только благодаря правильному проектированию программного кода, **нельзя** бездумно использовать параллельные вычисления и именованные состояния вместе, это приведет уже не просто к недетерминированному результату, а к настощему хаосу.

В случае когда нам всё таки нужно совмещать эти концепции, **мы должны** делать это в строго ограниченной, изолированной части системы, и код этот должен быть "грамотным" и выразительным.

Разумеется, в программной инженерии разработаны подходы к реализации совмещения переменных и concurrency.

### Атомарность

Один из способов решить проблему race condition — использовать атомарных операций.

Сначала вернемся к "состоянию гонки", и разберем его чуть подробнее. Представьте толкучку. Именно это и происходит когда параллельные нити пытаются работать с одними и теми же участками памяти. Кто успел — тот и съел. Потоки вычислений пытаются выполнить похожие действия и мешают друг другу.

Способ борьбы с этой ситуаций — построение thread-safe, или органазиация "*безопасности потока*". В язык программирования внедряются специальные инструкции, доступные разработчику для использования, которые позволяют объявить некоторые операции *атомарными*.

На практике это выглядит как *блокирование доступа к общей ячейке памяти* для других нитей, во время работы *"активной"* нити (та, которая "повесила" блокировку). Блокировка снимается когда активная нить завершила все необходимые ей операции с заблокированной ячейкой памяти.

Важный момент заключается в том, что хотя благодаря атомарности мы и изолируем ресурсы на время работы одной нити от других, сами они всё ещё могут, и запускаются в **непредсказуемом** порядке. То есть получается, что хотя thread-safe и является мощным инструментом-концепцией для устранения race condition, он не *избавляет нас от недеретминизма*.

Избавиться от недеретминизма при параллельных вычислениях можно, опять же, только правильным проектированием программы. Мы можем разделить атомарные операции по нитям таким образом, когда они, пусть и работают параллельно — результат становится детерминированным.  

### Железная параллельность

Хочется вкратце рассмотреть параллельность на уровне железа, работу многороцессорных систем.

Нам нужно понимать, что сначала именованные состояния попадают в ячейки оперативной памяти, и следом копируются по системной шине в *процессорные кэши*. Так как процессорных ядер у нас может быть несколько, параллельно работающие инструкции на разных ядрах могут стягивать в свой *локальный* кэш значения из памяти и по своему обрабатывать. В результате может получиться такая ситуация, когда в оперативной памяти у нас "изначальное" значение, а в локальных процессорных кэшах свои копии данных, да ещё и разные.

Разумеется, на практике существует решений этой проблемы, иначе как бы эта параллельность вообще работала? Мы точно не хотим иметь такой "race condition" на уровне железа, когда в операвную память будут возвращаться разные результаты работы из независимых (параллельно работающих) ядер.

Единство значений в локальных процессорных кэшах, для обеспечения корретной работы системы в целом, достигается благодаря так называемым *протоколам когерентности*.

Когерентность кэша (cache coherence) — *это свойство кэшей, подразумевающее консистентность (целостность) значений, которые записываются в локальные кэши каждого из процессорных ядер.*

Обеспечивается эта консистеность наличием у **каждой** ячейки кэша специальных флагов, от значений которых зависит то, как состояние хранимое в этой ячейке будет соотноситься с состояниями в ячейка кэша других ядер **имеющих такой же адрес**.

Например, когда состояние определенной ячейки меняется каким-либо образом, по внутренней сети процессорной системы происходит рассылка специльных сообщений (очень-очень быстро!).

На данный момент разработано много *протоколов когерентности*, которые отличаются алгоритмами работы и количеством состояний ячеек (флажков). Большая часть протоколов основаны на протоколе MESI (футболист тут не при чем!).

#### Протокол когерентности MESI

Важно подчеркнуть то, что данные между ячейками оперативной памяти и ячейками процессорного кэша передаются блоками фиксированных размеров, которые называют **линиями кэша**.

В схеме работы протокола MESI каждая линия кэша может находиться в одном из четырех состояний (те самые флаги):

1. Модифицированная линия (modified). Этим флагом одновременно может быть помечена только *одна* линия в *одном* локальном кэше. Очевидно из названия — флаг обозначает, что линия была как-то изменена, **но до оперативной памяти изменения ещё не доехали**. Ядро, к которому непосредственно относится эта линия может *без рассылки* уведомлений по внутреннй сети продолжать читать из ячейки и записывать в неё.

2. Эксклюзивная линия (exclusive). Так же как и модифицированная линия, эксклюзивная может находиться одновременно только в одном локальном кэше. Отличие в том, что данные в этой линии *идентичны* данным в соответствующей ячейке оперативной памяти. Чтение и запись в этой линии происходит без уведомлений, но после изменения данных линия помечается как *модифицированная*.

3. Разделямая линия (shared). Такая линия *может* содержаться одновременно в разных локальных кэшах, но запросы на изменение **всегда** отправляются в общую процессорную шину. Это приводит к тому, что все кэши других линий с таким же адресом отмечаются специальным флагом как *недействительные*.

4. Недействительная линия (invalid). Попытка чтения из кэша недействительной линии всегда проваливается (cache miss). Chace miss приводит к тому, что "свежие" данные должны быть прочитаны из оперативной памяти. Этим флагом помечаются либо пустые линии, либо содержащие устаревшие значения.

---

На практике работа процессорных кэшей, их внутреннее взаимодействиее и работа с оперативной памятью выглядит намного сложнее. Тему "железного" параллелизма мне захотелось затронуть, так как она является частью одного из вопросов в заключительном тесте по текущему курсу, и в качестве дополнительного акцента на разнице между concurrency и parallelism. Хочется верить что пост получился читаемым. Всех благ!
