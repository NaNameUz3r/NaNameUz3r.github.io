---
title: "Врубаемся в программирование"
tags: "Программирование Отчеты"
lang: ru
show_edit_on_github: false
comment: true
license: false
modify_date: "2022-01-30"
show_subscribe: false
article_header:
  theme: dark
  type: overlay
  align: left
  background_image:
    src: /header_images/hack_in_codding_1.jpg
---

Научный взгляд на программирование. Concurrency, atomicity и кое что ещё.
<!--more-->

В данный момент я прохожу курс Бобровского Сергея Игоревича, который называется "Как понять в программировании всё". На самом деле это цикл курсов, направленный на освоение научного, или лучше сказать — инженерного взгляда на программироваание, от фундаментальных концепций до осмысления *парадигм* программирования. 

Этот пост является отчетом о пройденном материале, больший фокус я хочу сделать на теме параллельного программирования и атомарности — я застрял на тесте по этой теме :), надеюсь вместе мы разберемся. В дополнение я постараюсь освятить некоторые важные концепции. Остальная и не затрагивамая в этом посте часть курса либо связана с синтаксисом и особенностями мультипарадигрмального языка программирования Julia, который изучается в рамках этого же курса, либо это отдельные и сложные концепции, которые пока мы затроули поверхностно, но обязательно вернемся позже (или я их плохо понял). Lets rock.

### Что там научного-то?

В посте про [сложность алгоритмов](/2022/01/22/algorithms_complexity.html) я пытался развить мысль о том, что программирование — дитя математики, и подходить к анализу и понимаю алгоритмов нужно с научно-математической позиции мышления, а не с интуитивно-наивной. С программированием всё обстоит точно-так же. Чтобы разрабатывать эффективные и надежные программные системы необходимо понимать как работает "под капотом" сама система, и инструменты которые для разработки этой системы используются (языки программирования, парадигмы, подходы к программированию, etc.). 

### Фундаментальные концепции 

#### Переменная 

Программе, или алгоритму, в процессе работы необходимо "пространство" в котором будут производиться вычисления. Этим пространством является оперативная память и процессорные кеши. Устройство оперативной памяти (и кешей) отдельная и сложная тема, сейчас нам нужно понимать что есть некоторый *ресурс* в который программа может быстро записывать какие-то данные, и читать их откуда. 

Проще всего представить оперативную память как набор ячеек, у которых есть адрес. По этому адреса с ячейками можно работать. В данном случае имеются в виду **физические** ячейки оперативной памяти.

В коде программы, в частном случае, мы напрямую (явно) с этими адресами не работаем, а используем *переменные* которым присваиваем *значения*. Имя переменной — это её идентификатор, а значениями являются какие-то данные, которые мы этому имени *присваиваем*, чаще всего с помощью оператора "=". 

Ещё более научно это называется *именованным состоянием*, что уже чуть более сложная концепция, которая является одной из главных характеристик в *любой* парадигме программирования, и реализация (степень поддержки) зависит от конкретно рассматриваемой парадигмы.

В общем и целом, *состояние* — это "способность" программы запоминать данные (присвоенные значения), в будущем с этими данными работать. Если состояние имеет идентификатор, то есть, напрямую и явно доступно для операций в исходном коде, то оно называется *"именованное состояние"*. Да, состояния могут не иметь идентификаторов и быть своего рода *безымянными*. 

##### Зачем идентификаторы, есть у ячеек есть адреса?

Во-первых, как я уже писал, мы с адресами напрямую, как правило, не работаем. Во-вторых, на самом деле значения ячейкам памяти присваиваются как "константа", то есть "на постоянку" и однократно (в момент присваивания). 

*"Однократное присваивание"* это одна из фундаментальных концепций программирования, суть которой в том, что как только в коде определяется переменная (некоторому идентификатору присваивется его "первое" значение), эта переменная становится неизменяемой (иммутабельной). 

Подождите, но я могу сделать в своем любимом пайтоне что-то вроде: my_special_var = "hello dear friend", и следом my_special_var = "goodbye fella", и расшибусь головой о стену от уверенности в том что print(my_special_var) вернёт последнюю строку — "goodbye fella". Всё так! Просто почти во всех современных языках программирования кроме концепции однократного присваивания переменных существует дополнительный механизм — уже упомянутое "явное определение", которое позволяет присвоить *новые* значения уже *существующему* идентификатору (переменной). Но использоваться, как правило, будет **не та же самая ячейка памяти**, а новая и с другим адресом. *Тот же самый, уже существующий идентификатор (имя переменной)* будет связан с другой областью (ячейкой) в памяти, в которую будет записано новое значение.

Не увлекайтесь "явным *переопределением*", это удобно, но есть один **серьезный минус** — потенциально эта возможность переопредления приводит к куче ошибок. Относитесь к переменным чутко и ответствено, используйте адекватный нейминг, старайтесь не переопределять уже существующие переменные (если нужно, используйте новые имена соответствующие контексту изменений и "смыслу кода"). Но так же не стоит плодить явно лишние переменные, а необходимые определяйте в непосредственной близости к коду, в котором эти переменные используются. Это короткое отступление о базовых приницпах "ясносного стиля" программирования :)

### Опять математика?

Как было сказано ранее, реализация "способности запоминать состояния" определяется поддерживаемыми языком программирования парадигмами программирования. 


{:refdef: style="text-align: center;"}
![Взрыв Мозга](/images/mind_blowing.gif)
{: refdef}
*<center>Поддерживаемые языком программирования парадигмы программирования — Чего-чего? </center>*

Не волнуйтесь, мы разберемся.

#### Парадигма программирования

Парадигмой программирования, грубо говоря, называется определённый подход к программной разработке. Правильно говоря — это не менее чем **настоящее** научное открытие, строго выверенная математическая теории, которая на практике в том или ином образе воплащается в сложных программных системах как *языки программированя*. Это не значит что язык программирования конструируется на базе одной парадигмы, напротив — многие современные языки являются мультипарадигмальными, из чего следует вывод что это *ну очень сложные математические модели*. 

*Хорошая новость в том, что если что-то придумали одни люди, мы можем в этом разобраться, пусть даже приложив усилия!*

Так вот, эта математическая модель выражается как *семантика языка программирования*, которая передает смысл конструкций (и инструкций) в конкретном языке программирования.

Подробное изучение парадигм программирования явно выходит за рамки этого поста и моих текущих знаний, но в будущем парадигмы будут подробнее изучаться на соответсвующих курсах, до которых я надеюсь добраться.

---

Способ реализации разобранного нами ранее *именованного состояния* является одной из двух ключевых характеристик парадигм программирования. Вторая характеристика — характерность или не характерность **недетерминизма**.

#### Недетерминизм

В привычном представлении новичка-программиста, особенно самоучки, привычная императивная программа выполняется последовательно и выдает от вызова к вызову с одними и теми-же аргументами один и тот-же результат. Такое поведение назвыается **детерминированным**. Иными словами, если программа детерминирована, мы можем по её коду однозначно определить какой результат будет на выходе. Никаких сюрпризов.

Недетерминизм, как несложно предположить, является противоположной ситуацией, когда вызывая программу, даже с одними и теми же входными данными, мы можем наблюдать разный результат из раза в раз. Такой недетерминизм называется *явным*. 

Но как такое получается? Программа может выдавать неожиданные результаты, если она описана в системе (парадигме) программирования, в которой соединяются уже изученные нами "именованные состояния" и ***параллельные*** вычисления.

### Параллелизм

Наконец мы подобрались к параллелизму! Сперва нам нужно строго определять о чем идет речь. В русском языке часто используется одно и то же слово для фактически разных концепции. 

Во-первых, есть parallelism — аппаратная концепция. Это про "одновременное" выполнение процессорных инструкций на нескольких ядрах, etc.

Во-вторых, concurrency — чисто программная концепция, которая нас интересует в первую очередь в рамках изучамых тем. Я далее буду использовать слово параллелизм, и по дефолту иметь в виду concurrency. В случае если речь вдруг зайдет про "процессорный параллелизм" на это будет явное указание. 

---

Вернемся к связи недетерминизма с параллельными вычислениями и именованными состояниями. В теме программного параллелизма есть две разные концепции:
- Процесс
- и Thread (нить).

Вспоминая свое начальное обучение на администратора баз данных, одно из самых интересных и ярких впечатлений у меня было вызвано простым, и чертовским понятным определением разницы этих двух терминов из записи одой из лекций Дмитрия Кетова об устройстве Линукса. Дословно не помню, но суть такая:

"Процесс — вычисления работающие в **изолированной** модели памяти. Нити — работают в модели **общей** памяти."

Иными словами, более научными и известными нам, Нити — это параллельные "процессы" которые могу иметь\имеют доступ к одним и тем же *именованным состояниям* (модель "общей" памяти).

Теперь должно стать понятно откуда берутся "неожиданные", недетерминированные результаты работы программы. Если в программе используются параллельные потоки (нити), которые работают с одними и теми-же переменными, мы **вообще** не можем знать в каком порядке эти нити буду запущены, изменят (перезапишут) значения переменной и завершатся. В таких условиях работы возникает race condition, по русски — "состояние гонки". Смысл этого термина в том, что "победителем" гонки будет нить, которая последней запишет в переменную результат своей работы. Отсюда и берутся уже упомянутый мной выше *явный недетерминизим*, мы видим его в непосредственном результате работы программы.

Хотя существуют ситуации, в которых недетерминизм приемлем или даже необходим (является целевым, ожидаемым результатом работы), чаще всего мы хотим чтобы наши программы были детерминированы (надежны и стабильны), даже применяя параллельные вычисления, в общем случае для ускорения работы программы. 

Такой результат может быть достигнут только благодаря правильному проектированию программного кода, **нельзя** использовать параллельные вычисления и именованные состояния вместе бездумно, это приведет уже не просто к недетерминированному результату, а к настощему хаосу. 

В случае когда нам всё таки нужно совмещать эти концепции, **мы должны** делать это в строго ограниченной, изолированной части кода (в программном модуле), и код этот должен быть "грамотным" и выразительным.

Разумеется, в программной инженерии разработаны подходы к реализации совмещения переменных и concurrency. Давайте рассмотрим один из них.

### Атомарность

Один из способов решить проблему race condition — использование атомарных операций. 

Сначала вернемся к "состоянию гонки", и разберем его чуть подробнее. Представьте толкучку. Именно это и происходит когда параллльные нити пытаются работать с одними и теми же участками памяти. Кто успел — тот и съел. Потоки вычислений пытаются выполнить похожие действия и мешают друг другу.

Способ борьбы с этой ситуаций называется thread-safe, или "*безопасность потока*". В язык программирования внедряются специальные инструкции, доступные разработчику для использования, которые позволяют объявить некоторые операции *атомарными*. 

На практике это выглядит как *блокирование доступа к общей ячейке памяти* для других нитей, во время работы *"активной"* нити (та, которая "повесила" блокировку). Блокировка снимается когда активная нить завершила все необходимые операции с заблокированной ячейкой памяти. 

Важный момент заключается в том, что хотя благодаря атомарности мы и изолируем на время работы одной нити используемые ресурсы от других нитей, сами нити всё ещё могут, и запускаются в **непредсказуемом** порядке. То есть получается, что хотя thread-safe и является мощным инструментом-концепций для устранения race condition, он не *избавляет нас от недеретминизма*.

Избавиться от недеретминизма при параллельных вычислениях можно, опять же, только правильным проектированием программы, когда мы логически разделяем по нитям вычисления так, что они хоть и работают параллельно и с общими переменными — результат становится детерминированным.  

### Железная параллельность

Хочется вкратце рассмотреть параллельность на уровне железа, работу многороцессорных систем.

В общем и целом нужно понимать, что сначала именованные состояния попадают в ячейки оперативной памяти, и следом копируются по системной шине в *процессорные кэши*. Так как процессорных ядер у нас может быть несколько, параллельно работающие инструкции на разных ядрах могут стягивать в свой *локальный* кэш значения из памяти и по своему обрабатывать. В результате может получиться такая ситуация, когда в оперативной памяти у нас "изначальное" значение, а в локальных кэшах процессорных ядер свои копии, да ещё и разные. 

Разумеется на практике существует решений этой проблемы, иначе как бы эта параллельность вообще работала? Мы точно не хотим иметь такой "race condition" на уровне железа, когда в операвную память будут возвращаться разные результаты работы из независимых (параллельно работающих) ядер. 

Единство значений в локальных кэшах проццессорных ядер, для обеспечения корретной работы системы в целом, достигается благодаря так называемым *протоколам когерентности*.

Когерентность кэша (cache coherence) — *это свойство кэшей, которое подразумевает консистентность (целостность) значений, которые записываются в локальные кэши каждого из процессорных ядер.*

Обеспечивается эта консистеность наличием у **каждой** ячейки кэша специальных флагов, от значений которых зависит как состояние, хранимое в этой ячейке, соотносится с состояниями в ячейка кэша других ядер **имеющих такой же адрес**.

Например, когда состояние определенной ячейки меняется каким-либо образом, по внутренней сети процессорной системы происходит рассылка специльных сообщений (очень-очень быстро!).

На данный момент разработано много *протоколов когерентности*, которые отличаются алгоритмами работы и количеством состояний ячеек (флажков). Большая часть протоколов основаны на протоколе MESI (футболист тут не при чем!).

#### Протокол когерентности MESI

Важно подчеркнуть то, что данные между ячейками оперативной памяти и ячейками процессорного кэша передаются блоками фиксированных размеров, которые называют **линиями кэша**. 

В схеме работы протокола MESI каждая линия кэша может находиться в одном из четырех состояний (те самые флаги):

1. Модифицированная линия (modified). Этим флагом одновременно может быть помечена только *одна* линия в *одном* локальном кэше. Очевидно из названия — флаг обозначает, что линия была как-то изменена, **но до оперативной памяти изменения ещё не доехали**. Ядро, к которому непосредственно относится эта линия может *без рассылки* уведомлений по внутреннй сети продолжать читать из ячейки и записывать в неё.

2. Эксклюзивная линия (exclusive). Так же как и модифицированная линия, эксклюзивная может находиться одновременно только в одном локальном кэше. Отличие в том, что данные в этой линии *идентичны* данным в соответствующей ячейке оперативной памяти. Чтение и запись в этой линии происходит без уведомлений, но после изменения данных линия помечается как *модифицированная*.

3. Разделямая линия (shared). Мы добрались до параллельности. Такая линия *может* содержаться одновременно в разных локальных кэшах, но запросы на изменение **всегда** отправляются в общую процессорную шину, это приводит к тому, что все кэши других линий с таким же адресом отмечаются специальным флагом как *недействительные*.

4. Недействительная линия (invalid). Попытка чтения из кэша недействительной линии проваливается (cache miss). Chace miss приводит к тому, что "свежие" данные должны быть прочитаны из оперативной памяти. Этим флагом помечаются либо пустые линии, либо содержащие устаревшие значения. 

---

На практике работа процессорных кэшей, их внутреннее взаимодействиее и взаимодействие с памятью выглядит намного сложнее. Тему "железного" параллелизма мне захотелось затронуть, так как она является частью одного из вопросов в заключительном тесте по текущему курсу, и в качестве дополнительного акцента на разнице между concurrency и parallelism. Хочется верить что пост получился читаемым. Всех благ!





